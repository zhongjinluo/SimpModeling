<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>SimpModeling: Sketching Implicit Field to Guide Mesh Modeling for 3D Animalmorphic Head Design</title>
    <link rel="stylesheet" href="w3.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
    <meta name="google-site-verification" content="vIrKe6Ecwa3TVjmMt0OaJpDGw_SJa5IxzTA86wU44QE" />
</head>

<body>

<br/>
<br/>

<div class="w3-container" id="paper">
    <div class="w3-content" style="max-width:850px">
  
    <h2 align="center" id="title"><b>SimpModeling: Sketching Implicit Field to Guide Mesh Modeling for 3D Animalmorphic Head Design</b></h2>
    <br/>
    <!-- <p align="center" id="title">Conference Name (NAME), YYYY.</p> -->

    <p align="center" class="center_text" id="authors">
        <a target="_blank" >Zhongjin Luo</a><sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" >Jie Zhou</a><sup>2</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank">Heming Zhu</a><sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" >Dong Du</a><sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" href="https://mypage.cuhk.edu.cn/academics/hanxiaoguang/">Xiaoguang Han</a><sup>1*</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" href="https://sweb.cityu.edu.hk/hongbofu/">Hongbo Fu</a><sup>2*</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;        
    </p>

    <p class="center_text" align="center" id="comments">
        <sup>*</sup>Corresponding email: hanxiaoguang@cuhk.edu.cn; hongbofu@cityu.edu.hk  
    </p>
    <p class="center_text" align="center">
        <sup>1</sup>SSE, The Chinese University of Hong Kong, Shenzhen
        &nbsp; &nbsp; &nbsp;
        <sup>2</sup>School of Creative Media, City University of Hong Kong 
        &nbsp; &nbsp; &nbsp;
    </p>

    <br>
    <center>
    <img src="paper-teaser.png" style="max-width:50%" /></a>
    </center><br>
<!--         <h4 align="center" id="title"><b>Submit to our ScanRefer Localization Benchmark <a href="http://kaldir.vc.in.tum.de/scanrefer_benchmark/" target="__blank">here</a>!</b></h4>
        <br><center><a href="http://kaldir.vc.in.tum.de/scanrefer_benchmark/" target="__blank"><img src="teaser.png" style="max-width:100%" /></a></center><br> -->

        
        <h3 class="w3-left-align" id="video"><b>Introduction</b></h3>
        <p>
            Caricature is an artistic representation that deliberately exaggerates the distinctive features of a human face to convey humor or sarcasm. However, reconstructing a 3D caricature from a 2D caricature image remains a challenging task, mostly due to the lack of data. 
            We propose to fill this gap by introducing 3DCaricShop, the first largescale 3D caricature dataset that contains 2000 high-quality diversified 3D caricatures manually crafted by professional artists. 3DCaricShop also provides rich annotations including a paired 2D caricature image, camera parameters and 3D facial landmarks.
            To demonstrate the advantage of 3DCaricShop, we present a novel baseline approach for single-view 3D caricature reconstruction. To ensure a faithful reconstruction with plausible face deformations, we propose to connect the good ends of the detailrich implicit functions and the parametric mesh representations. In particular, we first register a template mesh to the output of the implicit generator and iteratively project the registration result onto a pre-trained PCA space to resolve artifacts and self-intersections. To deal with the large deformation during non-rigid registration, we propose a novel view-collaborative graph convolution network (VCGCN) to extract key points from the implicit mesh for accurate alignment. 
            Our method is able to generate high-fidelity 3D caricature in a pre-defined mesh topology that is animation-ready. Extensive experiments have been conducted on 3DCaricShop to verify the significance of the database and the effectiveness of the proposed method. 

        </p>

        <h3 class="w3-left-align" id="video"><b>Video</b></h3>
        <p>
        Coming soon...
        <!--         <iframe width="850" height="480" src="https://www.youtube.com/embed/T9J5t-UEcNA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
         -->        
            <!--iframe width="850" height="480" src="vid.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe-->
        <p/>


        <h3 class="w3-left-align" id="publication"><b>Publication</b></h3>
        <!-- European Conference on Computer Vision (ECCV), 2020. <br/> -->
        <!-- <a href="davezchen_eccv2020_scanrefer.pdf" target="__blank">Paper</a>  -->
        Paper - Coming soon<!--<a href="https://arxiv.org/pdf/???" target="__blank">ArXiv - pdf</a> (<a href="https://arxiv.org/abs/2012.???" target="__blank">abs</a>)-->  | <a href="https://github.com/RudyQ/3DCaricShop" target="__blank">GitHub</a>
        <center>
            <a href="https://arxiv.org/pdf/2012.???" target="__blank"><img src="paper_preview.PNG" style="max-width:80%" /></a>
        </center><br>

        If you find our work useful, please consider citing it:
        <pre class="w3-panel w3-leftbar w3-light-grey" style="white-space: pre-wrap; font-family: monospace; font-size: 11px">

        
        Coming soon
        </pre>

        
        <h3 class="w3-left-align" id="dataset"><b>Dataset</b></h3>
        <center>
            <img src="paper-dataset.jpg" style="max-width:80%" /></a>
        </center><br>
        We contribute to 3DCaricShop dataset, a large collection to caricature face images and the corresponding 3D models manully crafted. The dataset proposed has serveral appealing features:
    </div>


</div>

<br/>
<br/>

</body>
</html>